{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ElABt1zNLfEG",
    "outputId": "8d64ef8e-5e1b-4973-ba1d-d55fdcc81ee1"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "juYcirlqrEaN",
    "outputId": "ad97a730-e2a9-4a64-ac76-49aeca96952d"
   },
   "outputs": [],
   "source": [
    "# Colab warns and provides remediation steps if the GPUs is not compatible with RAPIDS.\n",
    "\n",
    "!git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n",
    "!python rapidsai-csp-utils/colab/pip-install.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dCTZ8rVuPtLU"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from itertools import product\n",
    "import math\n",
    "import numpy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from scipy.cluster.hierarchy import dendrogram, leaves_list\n",
    "from scipy.spatial.distance import pdist\n",
    "from sklearn.manifold import TSNE, MDS\n",
    "import scipy\n",
    "# import umap\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import time\n",
    "\n",
    "import cupy as cp\n",
    "import cuml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uHoB-Kr0Lf99",
    "outputId": "1dd07157-f609-4f9a-ab54-982291cf2fcc"
   },
   "outputs": [],
   "source": [
    "from cuml.kernel_ridge import KernelRidge\n",
    "\n",
    "sys.path.append(os.path.abspath(\"/content/drive/MyDrive/UKP/\"))\n",
    "from distance_functions_final import *\n",
    "\n",
    "# Set the device for computation\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "lmbda_range = np.power(10.0, range(-7, 2))\n",
    "lmbda_range = np.concatenate((lmbda_range, [0]))\n",
    "sigma_range = np.power(10.0, range(-3, 3))\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "folder = \"/content/drive/MyDrive/UKP/mnist_experiments/distances/widthdepth/5000_train/\"\n",
    "folder_categorized = \"/content/drive/MyDrive/UKP/mnist_experiments/distances/widthdepth/5000_train_categorized\"\n",
    "# loading test distance file and seeing its entries\n",
    "data = np.load(f\"{folder}/width100_depth2_seed2_rep_width100_depth4_seed2_rep.npz\")\n",
    "print(data.files)\n",
    "\n",
    "distnames = data.files\n",
    "\n",
    "# Code to extract each different distance into its own array\n",
    "## done on Google colab using notebook separating distance into separate files.ipynb under mnist_experiments\n",
    "\n",
    "model_names = []\n",
    "reps_folder = f\"/content/drive/MyDrive/UKP-/mnist_experiments/reps/train/5000_eval\"\n",
    "filenames = os.listdir(reps_folder)\n",
    "for filename in filenames:\n",
    "  if \"saved\" not in filename and \"seed2\" in filename and \"depth3\" not in filename and \"depth6\" not in filename and \"depth8\":\n",
    "    model_names.append(filename[:-4])\n",
    "\n",
    "\n",
    "model_names = np.sort(model_names)\n",
    "num_models = len(model_names)\n",
    "\n",
    "dist_array = np.load(f'{folder_categorized}/all_distances_categorized.npz')\n",
    "\n",
    "# Loading representations (both train and test)\n",
    "\n",
    "rep_folder_prefix = '/content/drive/MyDrive/UKP/mnist_experiments/'\n",
    "train_reps_folder = rep_folder_prefix + 'reps/train/5000_eval/'\n",
    "val_reps_folder = rep_folder_prefix + 'reps/test/5000_eval/'\n",
    "\n",
    "dist_n = 5000\n",
    "# Load ImageNet representations\n",
    "reps_train = {}  # Train dataset\n",
    "reps_test = {}  # Validation dataset\n",
    "try:\n",
    "    for model_name in model_names:\n",
    "        print(model_name)\n",
    "        rep1 = np.load(train_reps_folder + model_name + \".npy\")\n",
    "\n",
    "        # use only dist_n samples\n",
    "        rep1 = rep1[:, :dist_n]\n",
    "\n",
    "        # center and normalize\n",
    "\n",
    "        rep1 = rep1 - rep1.mean(axis=1, keepdims=True)\n",
    "        rep1 = rep1 / np.linalg.norm(rep1)\n",
    "        rep1 = rep1 * np.sqrt(rep1.shape[1])\n",
    "        reps_train[model_name] = rep1\n",
    "\n",
    "        rep2 = np.load(val_reps_folder + model_name + \".npy\")\n",
    "\n",
    "        # Use only dist_n samples\n",
    "        rep2 = rep2[:, :dist_n]\n",
    "\n",
    "        # center and normalize\n",
    "        rep2 = rep2 - rep2.mean(axis=1, keepdims=True)\n",
    "        rep2 = rep2 / np.linalg.norm(rep2)\n",
    "        rep2 = rep2 * np.sqrt(rep2.shape[1])\n",
    "        reps_test[model_name] = rep2\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print('WARNING: IN ORDER TO RUN THIS CODE, THE IMAGENET REPRESENTATIONS MUST COMPUTED. SEE README.')\n",
    "    raise e\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fg3gTgCuTaBU",
    "outputId": "40e64644-cbfb-457a-d099-f70a4f355316"
   },
   "outputs": [],
   "source": [
    "def find_best_pred(y, lmbda, sigma, reps, kernelstr):\n",
    "    # ridge regression\n",
    "    # assume reps is dimension x number datapoints\n",
    "    rep_dim = reps.shape[0]\n",
    "    numpts = reps.shape[1]\n",
    "\n",
    "    if kernelstr == 'lap':\n",
    "        krr = CustomKernelRidge(alpha=lmbda, sigma=sigma)\n",
    "    if kernelstr == 'rbf':\n",
    "        gamma = 1/ ((2*sigma)**2)\n",
    "        krr = KernelRidge(alpha=lmbda, kernel='rbf', gamma = gamma)\n",
    "    krr.fit(reps.T, y) # If this does not work will go to dual coef\n",
    "    return krr\n",
    "\n",
    "\n",
    "def find_best_lin_pred(y, lmbda, reps):\n",
    "    # ridge regression\n",
    "    # assume reps is dimension x number datapoints\n",
    "    rep_dim = reps.shape[0]\n",
    "    numpts = reps.shape[1]\n",
    "\n",
    "    return np.linalg.solve((lmbda * np.eye(rep_dim) + (reps @ reps.T) / numpts), reps @ y)\n",
    "\n",
    "\n",
    "def symmetrize(A):\n",
    "    n = A.shape[0]\n",
    "    B = A.copy()\n",
    "    B[np.tril_indices(n)] = B.T[np.tril_indices(n)]\n",
    "    return B\n",
    "\n",
    "def dist_from_upper_tri_vec(vec, num_models):\n",
    "    D = np.zeros((num_models, num_models))\n",
    "    row_indices, col_indices = np.triu_indices(num_models, k=1)\n",
    "    D[row_indices, col_indices] = vec\n",
    "    D = symmetrize(D)\n",
    "\n",
    "    return D\n",
    "\n",
    "def flatten_upper_right_triangle(curr_mat):\n",
    "    cv = []\n",
    "    assert (curr_mat.shape[0] == curr_mat.shape[1])\n",
    "    assert (curr_mat.shape[0] == len(model_names))\n",
    "    for i in range(len(model_names) - 1):\n",
    "        for j in range(i + 1, len(model_names)):\n",
    "            cv.append(curr_mat[i, j])\n",
    "    cv = np.asarray(cv)\n",
    "    return cv\n",
    "\n",
    "def laplace_kernel(X, Y, sigma = 1.0):\n",
    "    return np.exp(-np.abs(X[:,np.newaxis] - Y[np.newaxis,:]) /sigma)\n",
    "\n",
    "distances = {}\n",
    "for i in range(len(distnames)):\n",
    "    distname = distnames[i]\n",
    "    print(distname)\n",
    "    distances[distname] = dist_from_upper_tri_vec(dist_array[distname],num_models)\n",
    "    print(distances[distname])\n",
    "\n",
    "### Upto this okay\n",
    "def get_collected_correlations_lintasks(lmbda, numtrials=50, numtrainsamples=5000):\n",
    "    collected_correlations = []\n",
    "\n",
    "    labels = []\n",
    "    # for ky, val in distances.items():\n",
    "    #     if ky != 'predictor_dist_range':\n",
    "    #         labels.append(ky)\n",
    "\n",
    "    for ky in distances.keys():\n",
    "        if ky != 'predictor_dist_range':\n",
    "            labels.append(ky)\n",
    "\n",
    "    for tri in range(numtrials):\n",
    "        print(f'Trial {tri}')\n",
    "\n",
    "        y = np.random.randn(numtrainsamples, 1) + 1\n",
    "\n",
    "        preds = {}\n",
    "        for model_name in model_names:\n",
    "            #         print(model_name)\n",
    "            preds[model_name] = find_best_lin_pred(y, lmbda, reps_train[model_name][:, 0:numtrainsamples])\n",
    "\n",
    "        #     # For each pair, compute the squared distance between predictions, averaged over test instances\n",
    "\n",
    "        errs = np.zeros((len(model_names), len(model_names)))\n",
    "        for ind1 in range(0, len(model_names) - 1):\n",
    "            for ind2 in range(ind1 + 1, len(model_names)):\n",
    "                cp1 = preds[model_names[ind1]].T @ reps_test[model_names[ind1]]\n",
    "                cp2 = preds[model_names[ind2]].T @ reps_test[model_names[ind2]]\n",
    "                #             print(cp1.shape)\n",
    "                errs[ind1, ind2] = np.linalg.norm(cp1 - cp2)\n",
    "                errs[ind2, ind1] = errs[ind1, ind2]\n",
    "        err_vec = flatten_upper_right_triangle(errs)\n",
    "\n",
    "        correlations = []\n",
    "\n",
    "        for distname in labels:\n",
    "            val = scipy.stats.spearmanr(err_vec, dist_array[distname]).correlation\n",
    "            correlations.append(val)\n",
    "\n",
    "        collected_correlations.append(correlations)\n",
    "\n",
    "    return labels, collected_correlations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5r7sGIEHccqG"
   },
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rr8ltIRNbnJw"
   },
   "outputs": [],
   "source": [
    "err_folder = f\"/content/drive/MyDrive/UKP/mnist_experiments/err_folder/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "28N2xlrbN1kv"
   },
   "outputs": [],
   "source": [
    "def get_collected_errs_kertasks(lmbda, sigma, numtrials=30, numtrainsamples=5000,numtestsamples=5000):\n",
    "    collected_RBF_correlations = []\n",
    "    # collected_Laplace_correlations = []\n",
    "\n",
    "    labels = []\n",
    "    # for ky, val in distances.items():\n",
    "    #     if ky != 'predictor_dist_range':\n",
    "    #         labels.append(ky)\n",
    "\n",
    "    for ky in distances.keys():\n",
    "        if ky != 'predictor_dist_range':\n",
    "            labels.append(ky)\n",
    "\n",
    "    for tri in range(numtrials):\n",
    "        print(f'Trial {tri}')\n",
    "\n",
    "        y = np.random.randn(numtrainsamples, 1) + 1\n",
    "\n",
    "        preds_RBF = {}\n",
    "        # preds_Laplace = {}\n",
    "        for model_name in model_names:\n",
    "            preds_RBF[model_name] = find_best_pred(y, lmbda, sigma, torch.tensor(reps_train[model_name][:, 0:numtrainsamples]).to(device), 'rbf')\n",
    "        #     # For each pair, compute the squared distance between predictions, averaged over test instances\n",
    "\n",
    "        errs_RBF = np.zeros((len(model_names), len(model_names)))\n",
    "        for ind1 in range(0, len(model_names) - 1):\n",
    "            print(f\"Doing i={ind1}\")\n",
    "            test_data_1 = torch.tensor(reps_test[model_names[ind1]][:, 0:numtestsamples]).T.to(device)\n",
    "            cp1_RBF = cp.asnumpy(preds_RBF[model_names[ind1]].predict(test_data_1))\n",
    "            for ind2 in range(ind1 + 1, len(model_names)):\n",
    "                print(f\"Doing i={ind1}. j={ind2}\")\n",
    "                test_data_2 = torch.tensor(reps_test[model_names[ind2]][:, 0:numtestsamples]).T.to(device)\n",
    "                cp2_RBF = cp.asnumpy(preds_RBF[model_names[ind2]].predict(test_data_2))\n",
    "                del test_data_2\n",
    "                gc.collect()\n",
    "                errs_RBF[ind1, ind2] = np.linalg.norm(cp1_RBF - cp2_RBF)\n",
    "                errs_RBF[ind2, ind1] = errs_RBF[ind1, ind2]\n",
    "\n",
    "            del test_data_1\n",
    "            gc.collect()\n",
    "             # Ensure all GPU operations are done\n",
    "            torch.cuda.synchronize()\n",
    "\n",
    "            # Clear GPU memory cache\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        err_RBF_vec = flatten_upper_right_triangle(errs_RBF)\n",
    "\n",
    "        np.save(f\"{err_folder}/{lmbda:7e}_{sigma:7e}_tri{tri}_numtrial{numtrials}_numtrainsamples{numtrainsamples}_err_RBF_vec.npy\", err_RBF_vec)\n",
    "        print(f\"Trial {i} Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1U8QO9yydGBC"
   },
   "outputs": [],
   "source": [
    "lmbda_range = np.array([np.power(10.0, -2), 1.0])\n",
    "sigma_range = np.array([np.power(10.0, -1), 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qMnBUGXBfN-z",
    "outputId": "11aed200-ac73-4952-8f45-e82ff0de512b"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "for lmbda_ind in range(len(lmbda_range)):\n",
    "  for sigma_ind in range(len(sigma_range)):\n",
    "    get_collected_errs_kertasks(lmbda_range[lmbda_ind], sigma_range[sigma_ind], numtrials=30, numtrainsamples=5000, numtestsamples=5000)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
